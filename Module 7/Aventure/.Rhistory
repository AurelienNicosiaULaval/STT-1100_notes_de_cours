meta_blocs
dates
# Vérification
tibble(titre = titres, producteur = producteurs, date = dates) |> print(n = 10)
titres
producteurs
# Extraire la date depuis la portion texte (avec regex sur le bloc HTML complet)
dates <- blocs |> map_chr(function(bloc) {
full_text <- html_text(bloc, trim = TRUE)
date_line <- stringr::str_extract(full_text, "Mis à jour le[^"]+")
meta_blocs
meta_blocs
page
# Extraction des titres, producteurs et catégories depuis donneesquebec.ca
library(rvest)
library(dplyr)
library(purrr)
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Catégorie", cats)][1]
gsub("^Catégorie : ", "", cat)
})
# Affichage
tibble(titre = titres, producteur = producteurs, categorie = categories) |> print(n = 10)
categories
producteurs
categories
# Extraction des titres, producteurs et catégories nettoyées depuis donneesquebec.ca
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories nettoyées
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[é|e]gorie", cats)][1]  # accepte "Catégorie" et "Catégories"
cat <- gsub("^Cat[é|e]gorie[s]* :\\s*", "", cat)
cat <- gsub("\\s*;\\s*", ", ", cat)  # remplace les ; par des ,
str_squish(cat)  # enlève les retours à la ligne et espaces inutiles
})
# Affichage
tibble(titre = titres, producteur = producteurs, categorie = categories) |> print(n = 10)
categories
producteurs
# Extraction des titres, producteurs et catégories nettoyées depuis donneesquebec.ca
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories nettoyées
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[é|e]gorie", cats)][1]  # accepte "Catégorie" et "Catégories"
cat <- gsub("^Cat[é|e]gorie[s]*\s*:\s*", "", cat)
# Catégories nettoyées
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[é|e]gorie", cats)][1]  # accepte "Catégorie" et "Catégories"
cat <- gsub("^Cat[é|e]gorie[s]*\s*:\s*", "", cat)
# Catégories nettoyées
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[é|e]gorie", cats)][1]  # accepte "Catégorie" et "Catégories"
cat <- gsub("^Cat[é|e]gorie[s]*\s*:\s*", "", cat)
# Extraction des titres, producteurs et catégories nettoyées depuis donneesquebec.ca
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories nettoyées
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[é|e]gorie", cats)][1]  # accepte "Catégorie" et "Catégories"
cat <- gsub("^Cat[é|e]gorie[s]*\s*:\s*", "", cat)
# Extraction des titres, producteurs et catégories nettoyées depuis donneesquebec.ca
library(rvest)
library(dplyr)
library(purrr)
library(stringr)
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
cat <- gsub("^Cat[ée]gorie[s]* *: *", "", cat)
cat <- gsub(";", ",", cat)
str_squish(cat)
})
# Affichage
tibble(titre = titres, producteur = producteurs, categorie = categories) |> print(n = 10)
blocs
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
bloc = blocs[[1]]
bloc
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cats
orgs[grepl("^Organisation", orgs)][1]
cats[grepl("^Organisation", orgs)][1]
cats[grepl("^Organisation", cats)][1]
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
car
cat
cat <- gsub("^Cat[ée]gorie[s]* *: *", "", cat)
cat
# Catégories
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
cat <- str_squish(cat)
cat <- gsub("^Cat[ée]gorie[s]*: ", "", cat)
cat <- gsub(";", ",", cat)
cat
})
categories
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cats
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
cat
cat <- str_squish(cat)
cat
cat <- gsub("^Cat[ée]gorie[s]* : ", "", cat)
cat
cat <- gsub(";", ",", cat)
cat
# Catégories
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
cat <- str_squish(cat)
cat <- gsub("^Cat[ée]gorie[s]* : ", "", cat)
cat <- gsub(";", ",", cat)
cat
})
# Affichage
tibble(titre = titres, producteur = producteurs, categorie = categories) |> print(n = 10)
# Fonction pour extraire les données d'une seule page
scrape_page <- function(url) {
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
# Titres
titres <- blocs |> html_node(".dataset-heading a") |> html_text(trim = TRUE)
# Producteurs
producteurs <- blocs |> map_chr(function(bloc) {
orgs <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
org <- orgs[grepl("^Organisation", orgs)][1]
gsub("^Organisation : ", "", org)
})
# Catégories
categories <- blocs |> map_chr(function(bloc) {
cats <- bloc |> html_nodes(".dqc-org-cat") |> html_text(trim = TRUE)
cat <- cats[grepl("^Cat[ée]gorie", cats)][1]
cat <- str_squish(cat)
cat <- gsub("^Cat[ée]gorie[s]* : ", "", cat)
cat <- gsub(";", ",", cat)
cat
})
tibble(
titre = titres,
producteur = producteurs,
categorie = categories
)
}
# Test sur une seule page
url_test <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc&page=1"
data_test <- scrape_page(url_test)
View(data_test)
# Test sur une seule page
url_test <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc&page=3"
data_test <- scrape_page(url_test)
View(data_test)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
blocs
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
url <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc"
page <- read_html(url)
# Blocs de contenu pour chaque jeu de données
blocs <- page |> html_nodes(".dataset-content")
blocs
blocs[1]
print(blocs[1])
blocs[1]|> html_text(trim = TRUE)
# Test sur une seule page
url_test <- "https://www.donneesquebec.ca/recherche/?sort=metadata_modified+desc&page=7"
data_test <- scrape_page(url_test)
data_test
readLines("https://www.donneesquebec.ca/robots.txt")
# Affichez le robots.txt
robots <- readLines("https://www.donneesquebec.ca/robots.txt")
cat("\nContenu du fichier robots.txt :\n")
writeLines(robots)
# Analyse rapide
disinstructions <- robots[grepl("^Disallow", robots)]
cat("\n\nChemins interdits aux robots :\n")
writeLines(disinstructions)
# Note éthique
cat("\n\n\u2139\ufe0f Note :\nLes jeux de données publics listés dans les pages de résultat ne sont pas explicitement restreints.\nLe scraping des pages principales de recherche est donc permis, tant qu'on évite les chemins /api/, /dataset/rate/, etc.\n")
# Exemple simplifié pour démonstration
exemple <- tibble::tibble(
id = 1:3,
semaine = c(1, 2, 3),
commentaire = c(
"Je trouve le cours motivant et bien structuré.",
"Cette semaine était difficile, j'ai eu du mal à suivre.",
"J'aime les exercices pratiques, ils m'aident à comprendre."
)
)
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
# Tokenisation + retrait des stopwords français
data(stop_words)
texte_nettoye <- exemple %>%
unnest_tokens(word, commentaire) %>%
filter(!word %in% stop_words$word,       # Retire les mots fréquents
str_detect(word, "^[a-z]+$"))     # Garde les mots alphabétiques uniquement
head(texte_nettoye)
stop_words$word
# Jeu de données fictif en français avec plus de commentaires
exemple <- tibble::tibble(
id = 1:6,
semaine = c(1, 1, 2, 2, 3, 3),
commentaire = c(
"J'ai trouvé le cours très clair cette semaine, bravo au prof !",
"Je commence à mieux comprendre, c'est motivant !",
"Trop de matière à assimiler en peu de temps, je me sens dépassé.",
"Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
"Les outils sont puissants, mais je manque de pratique.",
"La construction du dashboard est super intéressante."
)
)
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
# Charger les stopwords français
stop_fr <- stopwords::stopwords("fr", source = "snowball")
# Jeu de données fictif en français avec des commentaires
exemple <- tibble::tibble(
id = 1:6,
semaine = c(1, 1, 2, 2, 3, 3),
commentaire = c(
"J'ai trouvé le cours très clair cette semaine, bravo au prof !",
"Je commence à mieux comprendre, c'est motivant !",
"Trop de matière à assimiler en peu de temps, je me sens dépassé.",
"Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
"Les outils sont puissants, mais je manque de pratique.",
"La construction du dashboard est super intéressante."
)
)
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
# Charger les stopwords français
stop_fr <- stopwords::stopwords("fr", source = "snowball")
install.packages("stopwords")
library(stopwords)
# Charger les stopwords français
stop_fr <- stopwords::stopwords("fr", source = "snowball")
texte_nettoye <- exemple %>%
unnest_tokens(word, commentaire) %>%
filter(!word %in% stop_fr,             # Retirer les mots fréquents
str_detect(word, "^[a-zéèêàâîôûùçäëïöü]+$"))  # Garder les mots valides en français
head(texte_nettoye)
# Tokenisation + retrait des stopwords français
data(stop_words)
texte_nettoye <- exemple %>%
unnest_tokens(word, commentaire) %>%
filter(!word %in% stop_words$word,       # Retire les mots fréquents
str_detect(word, "^[a-z]+$"))     # Garde les mots alphabétiques uniquement
# Fusion avec un lexique de sentiment (ex: bing)
sentiment_bing <- texte_nettoye %>%
inner_join(get_sentiments("bing"), by = "word") %>%
count(semaine, sentiment) %>%
tidyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(score = positive - negative)
sentiment_bing
texte_nettoye %>%
inner_join(get_sentiments("bing"), by = "word")
get_sentiments("bing")
get_sentiments
# Installe si nécessaire
textdata::lexicon_afinn(lang = "fr")  # version traduite de AFINN
install.packages("textdata")
install.packages("textdata")
# Installe si nécessaire
textdata::lexicon_afinn(lang = "fr")  # version traduite de AFINN
# Lexique maison de base à adapter
lexique_fr <- tibble::tibble(
word = c("clair", "motivant", "bravo", "difficile", "dépassé", "mal", "intéressante", "puissants"),
sentiment = c("positive", "positive", "positive", "negative", "negative", "negative", "positive", "positive")
)
sentiment_fr <- texte_nettoye %>%
inner_join(lexique_fr, by = "word") %>%
count(semaine, sentiment) %>%
tidyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(score = positive - negative)
sentiment_fr
ggplot(sentiment_fr, aes(x = semaine, y = score)) +
geom_col(fill = "steelblue") +
labs(title = "Score de sentiment par semaine",
y = "Score net (positif - négatif)", x = "Semaine")
tfidf <- texte_nettoye %>%
count(semaine, word) %>%
bind_tf_idf(word, semaine, n) %>%
arrange(desc(tf_idf))
head(tfidf)
# Choisir semaine 2 comme exemple
library(forcats)
tfidf %>%
filter(semaine == 2) %>%
slice_max(tf_idf, n = 8) %>%
mutate(word = fct_reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Mots les plus distinctifs — Semaine 2",
x = NULL, y = "TF-IDF")
tfidf %>%
filter(semaine == 1) %>%
slice_max(tf_idf, n = 8) %>%
mutate(word = fct_reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Mots les plus distinctifs — Semaine 2",
x = NULL, y = "TF-IDF")
tfidf %>%
filter(semaine == 3) %>%
slice_max(tf_idf, n = 8) %>%
mutate(word = fct_reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Mots les plus distinctifs — Semaine 2",
x = NULL, y = "TF-IDF")
# Jeu de données fictif en français avec des commentaires
exemple <- tibble::tibble(
id = 1:6,
semaine = c(1, 1, 2, 2, 3, 3),
commentaire = c(
"J'ai trouvé le cours très clair cette semaine, bravo au prof !",
"Je commence à mieux comprendre, c'est motivant !",
"Trop de matière à assimiler en peu de temps, je me sens dépassé.",
"Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
"Ouf très difficile cette semaine, particulièrement avec les graphiques",
"Les outils sont puissants, mais je manque de pratique.",
"La construction du dashboard est super intéressante."
)
)
# Jeu de données fictif en français avec des commentaires
exemple <- tibble::tibble(
id = 1:6,
semaine = c(1, 1, 2, 2, 3, 3),
commentaire = c(
"J'ai trouvé le cours très clair cette semaine, bravo au prof !",
"Je commence à mieux comprendre, c'est motivant !",
"Trop de matière à assimiler en peu de temps, je me sens dépassé.",
"Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
"Ouf très difficile cette semaine, particulièrement avec les graphiques.",
"Les outils sont puissants, mais je manque de pratique.",
"La construction du dashboard est super intéressante."
)
)
# Jeu de données fictif en français avec des commentaires
exemple <- tibble::tibble(
id = 1:7,
semaine = c(1, 1, 2, 2, 2, 3, 3),
commentaire = c(
"J'ai trouvé le cours très clair cette semaine, bravo au prof !",
"Je commence à mieux comprendre, c'est motivant !",
"Trop de matière à assimiler en peu de temps, je me sens dépassé.",
"Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
"Ouf très difficile cette semaine, particulièrement avec les graphiques.",
"Les outils sont puissants, mais je manque de pratique.",
"La construction du dashboard est super intéressante."
)
)
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
library(stopwords)
# Charger les stopwords français
stop_fr <- stopwords::stopwords("fr", source = "snowball")
texte_nettoye <- exemple %>%
unnest_tokens(word, commentaire) %>%
filter(!word %in% stop_fr,             # Retirer les mots fréquents
str_detect(word, "^[a-zéèêàâîôûùçäëïöü]+$"))  # Garder les mots valides en français
head(texte_nettoye)
# Lexique maison de base à adapter
lexique_fr <- tibble::tibble(
word = c("clair", "motivant", "bravo", "difficile", "dépassé", "mal", "intéressante", "puissants"),
sentiment = c("positive", "positive", "positive", "negative", "negative", "negative", "positive", "positive")
)
sentiment_fr <- texte_nettoye %>%
inner_join(lexique_fr, by = "word") %>%
count(semaine, sentiment) %>%
tidyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(score = positive - negative)
sentiment_fr
ggplot(sentiment_fr, aes(x = semaine, y = score)) +
geom_col(fill = "steelblue") +
labs(title = "Score de sentiment par semaine",
y = "Score net (positif - négatif)", x = "Semaine")
tfidf <- texte_nettoye %>%
count(semaine, word) %>%
bind_tf_idf(word, semaine, n) %>%
arrange(desc(tf_idf))
head(tfidf)
# Choisir semaine 2 comme exemple
library(forcats)
tfidf %>%
filter(semaine == 2) %>%
slice_max(tf_idf, n = 8) %>%
mutate(word = fct_reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Mots les plus distinctifs — Semaine 2",
x = NULL, y = "TF-IDF")
# Choisir semaine 2 comme exemple
library(forcats)
tfidf %>%
filter(semaine == 2) %>%
slice_max(tf_idf, n = 8) %>%
mutate(word = fct_reorder(word, tf_idf)) %>%
ggplot(aes(x = word, y = tf_idf)) +
geom_col(fill = "darkorange") +
coord_flip() +
labs(title = "Mots les plus distinctifs — Semaine 2",
x = NULL, y = "TF-IDF")
# install.packages("devtools")
devtools::install_github("IlhemB/ssmmHMM")
install.packages("combinat")
# install.packages("devtools")
devtools::install_github("IlhemB/ssmmHMM")
# install.packages("devtools")
devtools::install_github("AurelienNicosiaUlaval/ssmmHMM")
library(ggplot2)
# install.packages("devtools")
devtools::install_github("AurelienNicosiaUlaval/ssmmHMM")
devtools::install_github("IlhemB/ssmmHMM@aurelien-1")
# install.packages("devtools")
devtools::install_github("AurelienNicosiaUlaval/ssmmHMM@aurelien-1")
