---
title: "Aventure 10 — Au-delà des données : texte et tableau de bord"
subtitle: "STT-1100 • Introduction à la science des données"
format:
  html:
    toc: true
    toc-title: "Plan de l’aventure"
    embed-resources: true
    link-external-newwindow: true
    code-link: true
    theme: flatly
    css: [../../css/base_css.css]
editor: visual
editor_options:
  chunk_output_type: console
---



# ✈️ Mise en contexte

Cette semaine, vous avez été **engagé·e comme analyste d'affaires junior** par la **Faculté des sciences et de génie de l'Université Laval**. Dans le cadre de la réforme du baccalauréat en statistique et science des données, la direction souhaite évaluer **l’évolution du ressenti étudiant tout au long de la session**.

Chaque semaine, les étudiant·es ont répondu à un questionnaire sur leur expérience d’apprentissage dans le cours STT-1100. Vos analyses seront essentielles pour documenter les points forts et les pistes d’amélioration du nouveau programme.

Vous êtes guidé·e par **Anne-Sophie**, la directrice du programme, qui vous accompagne dans la structuration de votre tableau de bord et vous aide à interpréter les résultats.

> "L’idée, c’est d’avoir un portrait honnête, mais constructif. On veut voir les tendances de fond et s’en inspirer pour continuer d’améliorer notre programme."

# 🎯 Mission

Construire un tableau de bord interactif (avec `flexdashboard` et `shiny`) qui permet de :

- visualiser les sentiments exprimés par semaine,
- identifier les mots les plus fréquents et distinctifs,
- explorer les tendances lexicales dans le temps,
- offrir des filtres dynamiques pour affiner l’analyse.

# 📁 Données

Un fichier `sentiments_cours.csv` contient :

- `id`: identifiant anonyme
- `semaine`: numéro de semaine
- `commentaire`: texte libre sur leur ressenti face au cours cette semaine
- `difficulte`: niveau de difficulté perçu (1 à 5)
- `engagement`: niveau d’engagement (1 à 5)
- `plaisir`: niveau de plaisir (1 à 5)

# 🧰 Outils recommandés

- `tidytext`, `stringr`, `dplyr` : nettoyage et analyse du texte
- `ggplot2`, `wordcloud`, `plotly` : visualisation
- `flexdashboard`, `shiny` : interface interactive
- `lexique` : `bing`, `afinn`, ou `nrc` (pour l’analyse de sentiment)

# 🧪 Étapes guidées

## Étape 1 — Nettoyage de texte

::: {.callout-important title="🧑‍💼 - Question d’Anne-Sophie"}
« Est-ce que tu pourrais me montrer un exemple avec quelques commentaires et comment tu les nettoierais étape par étape ? »
:::

::: {.callout-tip title="🧑‍💼 - Petit rappel"}
Le nettoyage de texte est essentiel avant toute analyse. Tu veux que chaque mot ait un sens pertinent. Essaie de retirer la ponctuation, les mots trop courants, et assure-toi que tout est bien en minuscules.
:::

::: {.callout-note title="🔎 Notions clés"}
- **Tokenisation** : procédé qui consiste à découper le texte en unités de base (mots, n‑grammes). Chaque token devient une ligne dans votre tableau.
- **Stopwords** : mots très fréquents ("le", "de", "et", etc.) qui n'apportent généralement pas d'information sémantique utile pour l'analyse.
- **Nettoyage** : mise en minuscules, retrait de la ponctuation, chiffres et caractères spéciaux pour normaliser les tokens.
:::

### Exemple de jeu de données simulé

```{r}
# Jeu de données fictif en français avec des commentaires
exemple <- tibble::tibble(
  id = 1:7,
  semaine = c(1, 1, 2, 2, 2, 3, 3),
  commentaire = c(
    "J'ai trouvé le cours très clair cette semaine, bravo au prof !",
    "Je commence à mieux comprendre, c'est motivant !",
    "Trop de matière à assimiler en peu de temps, je me sens dépassé.",
    "Pas facile cette semaine, j’ai eu du mal avec les graphiques.",
    "Ouf très difficile cette semaine, particulièrement avec les graphiques.",
    "Les outils sont puissants, mais je manque de pratique.",
    "La construction du dashboard est super intéressante."
  )
)
```

### Prétraitement du texte

```{r messge=FALSE, warning=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
library(stopwords)

# Charger les stopwords français
stop_fr <- stopwords::stopwords("fr", source = "snowball")

texte_nettoye <- exemple %>%
  unnest_tokens(word, commentaire) %>%
  filter(!word %in% stop_fr,             # Retirer les mots fréquents
         str_detect(word, "^[a-zéèêàâîôûùçäëïöü]+$"))  # Garder les mots valides en français

head(texte_nettoye)
```



::: {.callout-important title="🧑‍💼 - Question d’Anne-Sophie"}
« Est-ce que tu pourrais me montrer un exemple avec quelques commentaires et comment tu les nettoierais étape par étape ? »
:::

Anne-Sophie vous demande d'appliquer un nettoyage classique :

- retirer la ponctuation, les chiffres et les mots fréquents (stopwords),

- transformer le texte en minuscules,

- **tokeniser** le texte (découper en mots).

## Étape 2 — Analyse de sentiment

On s'intéresse ici à la **valence émotionnelle** des mots dans les commentaires. L'analyse de sentiment permet de quantifier si un texte est plutôt positif ou négatif.

::: {.callout-note title="🔎 Notions clés"}
- **Sentiment d’un mot** : étiquette (positive, négative) ou score numérique indiquant la valence émotionnelle du mot.
- **Score de sentiment d’un texte** : somme ou différence des scores/étiquettes des mots qu'il contient, souvent agrégé par document ou, ici, par semaine.
:::

### Analyse de sentiment en français

Actuellement, il **n'existe pas de lexique intégré à `tidytext::get_sentiments()` pour le français** (contrairement à l'anglais, où les lexiques `bing`, `afinn`, et `nrc` sont directement accessibles). Voici donc une approche pédagogique : créer un petit lexique personnalisé à enrichir en classe.

::: {.callout-important title="🧑‍💼 - Suggestion d’Anne-Sophie"}
« Pour cette étape, je vous recommande de construire un petit lexique maison. Vous pouvez commencer par les mots qui reviennent souvent et les classer subjectivement. Le but ici est de comprendre le principe d'une analyse de sentiment, même avec des outils simples. »
:::

```{r}
# Lexique maison de base à adapter
lexique_fr <- tibble::tibble(
  word = c("clair", "motivant", "bravo", "difficile", "dépassé", "mal", "intéressante", "puissants"),
  sentiment = c("positive", "positive", "positive", "negative", "negative", "negative", "positive", "positive")
)

sentiment_fr <- texte_nettoye %>%
  inner_join(lexique_fr, by = "word") %>%
  count(semaine, sentiment) %>%
  tidyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(score = positive - negative)

sentiment_fr
```





### Visualisation des scores par semaine

Faisons un graphique pour visualiser l'évolution du score de sentiment par semaine :

```{r}
ggplot(sentiment_fr, aes(x = semaine, y = score)) +
  geom_col(fill = "steelblue") +
  labs(title = "Score de sentiment par semaine",
       y = "Score net (positif - négatif)", x = "Semaine")
```

::: {.callout-note title="🧑‍💼 - Conseil d’Anne-Sophie"}
« Comme les lexiques intégrés à `get_sentiments()` ne sont disponibles qu’en anglais, je vous propose de construire un petit lexique maison pour le français. Ce sera imparfait, mais cela vous permettra de comprendre le principe. On pourra ensuite en discuter ensemble pour l’enrichir. Ce qui m'intéresse, c’est que vous soyez capables d’interpréter l’évolution du sentiment d'une semaine à l’autre, même avec des outils simples. »
:::


### 🤝 Collaboration finale

À la fin du cours, une activité en classe permettra à chaque étudiants/équipes de **partager son propre lexique de sentiments en français** construit durant l’analyse. 

🎓 **L’enseignant collectera et fusionnera ces lexiques**, en les vérifiant pour en retirer une version enrichie commune. Cette nouvelle version sera partagée avec toute la classe comme ressource collective pour les projets futurs.



## Étape 3 — Mots distinctifs

Dans cette étape, nous allons identifier les mots qui ressortent le plus chaque semaine. Pour cela, nous utiliserons l'approche **TF-IDF** (Term Frequency-Inverse Document Frequency), qui permet de mettre en évidence les mots à la fois fréquents dans un document et rares dans l'ensemble des documents.

::: {.callout-tip title="🧑‍💼 - Idée d’Anne-Sophie"}
« Un bon indicateur de ce que ressentent les étudiant·es, ce sont les mots qui ressortent le plus dans leurs commentaires. Vous pouvez essayer une analyse TF-IDF ou même créer un nuage de mots. »
:::

::: {.callout-note title="🔎 Notions clés"}
- **TF (Term Frequency)** : fréquence d’apparition d’un mot dans un document.
- **IDF (Inverse Document Frequency)** : importance inverse d’un mot dans l’ensemble des documents – les mots rares ont un IDF élevé.
- **TF‑IDF** : produit TF × IDF qui met en évidence les mots à la fois fréquents dans un document et rares dans les autres (mots "distinctifs").
:::

### Calcul TF-IDF

Calculons le TF-IDF pour chaque mot par semaine :

```{r}
tfidf <- texte_nettoye %>%
  count(semaine, word) %>%
  bind_tf_idf(word, semaine, n) %>%
  arrange(desc(tf_idf))

head(tfidf)
```

### Visualisation pour une semaine donnée

Faisons un graphique pour visualiser les mots les plus distinctifs pour une semaine spécifique. Par exemple, la semaine 2 :

```{r}
# Choisir semaine 2 comme exemple
library(forcats)

tfidf %>%
  filter(semaine == 2) %>%
  slice_max(tf_idf, n = 8) %>%
  mutate(word = fct_reorder(word, tf_idf)) %>%
  ggplot(aes(x = word, y = tf_idf)) +
  geom_col(fill = "darkorange") +
  coord_flip() +
  labs(title = "Mots les plus distinctifs — Semaine 2",
       x = NULL, y = "TF-IDF")
```

Une visualisation comme celle-ci permet de voir quels mots sont les plus représentatifs des commentaires de cette semaine-là. Il existe aussi la possibilité de créer un **nuage de mots** pour une représentation plus visuelle. Un nuage de mot est une représentation graphique des mots les plus fréquents, où la taille de chaque mot est proportionnelle à sa fréquence d'apparition.

💡 Pour créer un nuage de mots en français :
- Utilisez la fonction `wordcloud()` du package `wordcloud`, ou `ggwordcloud` pour plus de personnalisation.
- Inspirez-vous de cet exemple complet : [https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html](https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html)

::: {.callout-important title="🧑‍💼 - Question d’Anne-Sophie"}
« Peux-tu repérer les mots qui ressortent le plus chaque semaine ? Tu pourrais essayer une approche TF-IDF et me faire un graphique ou même un nuage de mots. »
:::


## Étape 4 — Création du dashboard

Maintenant que nous avons nettoyé les données et effectué les analyses de sentiment et de mots distinctifs, il est temps de créer un tableau de bord interactif. Celui-ci permettra à Anne-Sophie de visualiser les résultats de manière claire et dynamique.

::: {.callout-note title="🧑‍💼 - Rappel d’Anne-Sophie"}
Le tableau de bord final doit être **clair, interactif et utile**. Un **modèle prêt à l’emploi (`Modele_Dashboardt.Rmd`)** se trouve dans le dépôt GitHub du module. Personnalisez‑le : branchez vos propres données, ajustez les filtres, et ajoutez au moins deux visualisations.
:::
## Étape 5 — Recommandations et analyse finale

À la fin du tableau de bord, rédigez un résumé de vos **observations clés** :

- évolution du score de sentiment,
- semaines critiques,
- recommandations d’action pour améliorer l’expérience étudiante,
- **analyse des variables numériques** `difficulte`, `engagement`, `plaisir` : moyenne et tendance par semaine, comparaison avec le score de sentiment (ex. corrélations simples ou graphiques combinés).

::: {.callout-important title="🧑‍💼 - Défi d’Anne-Sophie"}
« N’oubliez pas d’explorer les scores numériques. Comment le sentiment textuel se compare‑t‑il au niveau de plaisir ou de difficulté perçue ? Présentez au moins une visualisation qui croise ces informations. »
:::

# 🌟 Bonus — Personnalisation — Personnalisation

Voici quelques idées pour aller plus loin dans la personnalisation de votre tableau de bord :

- Ajouter le **logo de la Faculté des sciences et de génie** ou de l’Université Laval,
- Personnaliser la **palette de couleurs** pour qu’elle soit cohérente avec l’identité visuelle ULaval,
- Ajouter une **photo de fond** discrète dans l’en-tête,
- Ajouter une citation inspirante ou un message d'accueil dans la barre latérale.

💡 Vous pouvez également intégrer une barre de progression ou un indicateur visuel du sentiment général par semaine.

# 📤 Livraison attendue

- Un dépôt GitHub contenant :
  - le `.Rmd` du tableau de bord,
  - le rendu HTML final,
  - le fichier de données nettoyé (si modifié).
- **Le tableau de bord doit être déployé (par exemple via Shinyapp.io ou Posit Cloud)** et le lien final envoyé à **Anne-Sophie (la véritable directrice du programme)**.

# 🧠 Conseils d’Anne-Sophie

> « Un bon tableau de bord, c’est comme un bon pitch : **clair, lisible et ciblé**. Mettez-vous à la place de votre utilisateur final. »
