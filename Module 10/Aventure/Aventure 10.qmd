---
title: "Aventure 10 â€” Au-delÃ  des donnÃ©es : texte et tableau de bord"
subtitle: "STT-1100 â€¢ Introduction Ã  la science des donnÃ©es"
format:
  html:
    toc: true
    toc-title: "Plan de lâ€™aventure"
    embed-resources: true
    link-external-newwindow: true
    code-link: true
    theme: flatly
    css: [../../css/base_css.css]
editor: visual
editor_options:
  chunk_output_type: console
---



# âœˆï¸ Mise en contexte

Cette semaine, vous avez Ã©tÃ© **engagÃ©Â·e comme analyste d'affaires junior** par la **FacultÃ© des sciences et de gÃ©nie de l'UniversitÃ© Laval**. Dans le cadre de la rÃ©forme du baccalaurÃ©at en statistique et science des donnÃ©es, la direction souhaite Ã©valuer **lâ€™Ã©volution du ressenti Ã©tudiant tout au long de la session**.

Chaque semaine, les Ã©tudiantÂ·es ont rÃ©pondu Ã  un questionnaire sur leur expÃ©rience dâ€™apprentissage dans le cours STT-1100. Vos analyses seront essentielles pour documenter les points forts et les pistes dâ€™amÃ©lioration du nouveau programme.

Vous Ãªtes guidÃ©Â·e par **Anne-Sophie**, la directrice du programme, qui vous accompagne dans la structuration de votre tableau de bord et vous aide Ã  interprÃ©ter les rÃ©sultats.

> "Lâ€™idÃ©e, câ€™est dâ€™avoir un portrait honnÃªte, mais constructif. On veut voir les tendances de fond et sâ€™en inspirer pour continuer dâ€™amÃ©liorer notre programme."

# ğŸ¯ Mission

Construire un tableau de bord interactif (avec `flexdashboard` et `shiny`) qui permet de :

- visualiser les sentiments exprimÃ©s par semaine,
- identifier les mots les plus frÃ©quents et distinctifs,
- explorer les tendances lexicales dans le temps,
- offrir des filtres dynamiques pour affiner lâ€™analyse.

# ğŸ“ DonnÃ©es

Un fichier `sentiments_cours.csv` contient :

- `id`: identifiant anonyme
- `semaine`: numÃ©ro de semaine
- `commentaire`: texte libre sur leur ressenti face au cours cette semaine
- `difficulte`: niveau de difficultÃ© perÃ§u (1 Ã  5)
- `engagement`: niveau dâ€™engagement (1 Ã  5)
- `plaisir`: niveau de plaisir (1 Ã  5)

# ğŸ§° Outils recommandÃ©s

- `tidytext`, `stringr`, `dplyr` : nettoyage et analyse du texte
- `ggplot2`, `wordcloud`, `plotly` : visualisation
- `flexdashboard`, `shiny` : interface interactive
- `lexique` : `bing`, `afinn`, ou `nrc` (pour lâ€™analyse de sentiment)

# ğŸ§ª Ã‰tapes guidÃ©es

## Ã‰tape 1 â€” Nettoyage de texte

::: {.callout-important title="ğŸ§‘â€ğŸ’¼ - Question dâ€™Anne-Sophie"}
Â« Est-ce que tu pourrais me montrer un exemple avec quelques commentaires et comment tu les nettoierais Ã©tape par Ã©tape ? Â»
:::

::: {.callout-tip title="ğŸ§‘â€ğŸ’¼ - Petit rappel"}
Le nettoyage de texte est essentiel avant toute analyse. Tu veux que chaque mot ait un sens pertinent. Essaie de retirer la ponctuation, les mots trop courants, et assure-toi que tout est bien en minuscules.
:::

::: {.callout-note title="ğŸ” Notions clÃ©s"}
- **Tokenisation**â€¯: procÃ©dÃ© qui consiste Ã  dÃ©couper le texte en unitÃ©s de base (mots, nâ€‘grammes). Chaque token devient une ligne dans votre tableau.
- **Stopwords**â€¯: mots trÃ¨s frÃ©quents ("le", "de", "et", etc.) qui n'apportent gÃ©nÃ©ralement pas d'information sÃ©mantique utile pour l'analyse.
- **Nettoyage**â€¯: mise en minuscules, retrait de la ponctuation, chiffres et caractÃ¨res spÃ©ciaux pour normaliser les tokens.
:::

### Exemple de jeu de donnÃ©es simulÃ©

```{r}
# Jeu de donnÃ©es fictif en franÃ§ais avec des commentaires
exemple <- tibble::tibble(
  id = 1:7,
  semaine = c(1, 1, 2, 2, 2, 3, 3),
  commentaire = c(
    "J'ai trouvÃ© le cours trÃ¨s clair cette semaine, bravo au prof !",
    "Je commence Ã  mieux comprendre, c'est motivant !",
    "Trop de matiÃ¨re Ã  assimiler en peu de temps, je me sens dÃ©passÃ©.",
    "Pas facile cette semaine, jâ€™ai eu du mal avec les graphiques.",
    "Ouf trÃ¨s difficile cette semaine, particuliÃ¨rement avec les graphiques.",
    "Les outils sont puissants, mais je manque de pratique.",
    "La construction du dashboard est super intÃ©ressante."
  )
)
```

### PrÃ©traitement du texte

```{r messge=FALSE, warning=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
library(stopwords)

# Charger les stopwords franÃ§ais
stop_fr <- stopwords::stopwords("fr", source = "snowball")

texte_nettoye <- exemple %>%
  unnest_tokens(word, commentaire) %>%
  filter(!word %in% stop_fr,             # Retirer les mots frÃ©quents
         str_detect(word, "^[a-zÃ©Ã¨ÃªÃ Ã¢Ã®Ã´Ã»Ã¹Ã§Ã¤Ã«Ã¯Ã¶Ã¼]+$"))  # Garder les mots valides en franÃ§ais

head(texte_nettoye)
```



::: {.callout-important title="ğŸ§‘â€ğŸ’¼ - Question dâ€™Anne-Sophie"}
Â« Est-ce que tu pourrais me montrer un exemple avec quelques commentaires et comment tu les nettoierais Ã©tape par Ã©tape ? Â»
:::

Anne-Sophie vous demande d'appliquer un nettoyage classique :

- retirer la ponctuation, les chiffres et les mots frÃ©quents (stopwords),

- transformer le texte en minuscules,

- **tokeniser** le texte (dÃ©couper en mots).

## Ã‰tape 2 â€” Analyse de sentiment

On s'intÃ©resse ici Ã  la **valence Ã©motionnelle** des mots dans les commentaires. L'analyse de sentiment permet de quantifier si un texte est plutÃ´t positif ou nÃ©gatif.

::: {.callout-note title="ğŸ” Notions clÃ©s"}
- **Sentiment dâ€™un mot**â€¯: Ã©tiquette (positive, nÃ©gative) ou score numÃ©rique indiquant la valence Ã©motionnelle du mot.
- **Score de sentiment dâ€™un texte**â€¯: somme ou diffÃ©rence des scores/Ã©tiquettes des mots qu'il contient, souvent agrÃ©geÌ par document ou, ici, par semaine.
:::

### Analyse de sentiment en franÃ§ais

Actuellement, il **n'existe pas de lexique intÃ©grÃ© Ã  `tidytext::get_sentiments()` pour le franÃ§ais** (contrairement Ã  l'anglais, oÃ¹ les lexiques `bing`, `afinn`, et `nrc` sont directement accessibles). Voici donc une approche pÃ©dagogique : crÃ©er un petit lexique personnalisÃ© Ã  enrichir en classe.

::: {.callout-important title="ğŸ§‘â€ğŸ’¼ - Suggestion dâ€™Anne-Sophie"}
Â« Pour cette Ã©tape, je vous recommande de construire un petit lexique maison. Vous pouvez commencer par les mots qui reviennent souvent et les classer subjectivement. Le but ici est de comprendre le principe d'une analyse de sentiment, mÃªme avec des outils simples. Â»
:::

```{r}
# Lexique maison de base Ã  adapter
lexique_fr <- tibble::tibble(
  word = c("clair", "motivant", "bravo", "difficile", "dÃ©passÃ©", "mal", "intÃ©ressante", "puissants"),
  sentiment = c("positive", "positive", "positive", "negative", "negative", "negative", "positive", "positive")
)

sentiment_fr <- texte_nettoye %>%
  inner_join(lexique_fr, by = "word") %>%
  count(semaine, sentiment) %>%
  tidyr::pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(score = positive - negative)

sentiment_fr
```





### Visualisation des scores par semaine

Faisons un graphique pour visualiser l'Ã©volution du score de sentiment par semaine :

```{r}
ggplot(sentiment_fr, aes(x = semaine, y = score)) +
  geom_col(fill = "steelblue") +
  labs(title = "Score de sentiment par semaine",
       y = "Score net (positif - nÃ©gatif)", x = "Semaine")
```

::: {.callout-note title="ğŸ§‘â€ğŸ’¼ - Conseil dâ€™Anne-Sophie"}
Â« Comme les lexiques intÃ©grÃ©s Ã  `get_sentiments()` ne sont disponibles quâ€™en anglais, je vous propose de construire un petit lexique maison pour le franÃ§ais. Ce sera imparfait, mais cela vous permettra de comprendre le principe. On pourra ensuite en discuter ensemble pour lâ€™enrichir. Ce qui m'intÃ©resse, câ€™est que vous soyez capables dâ€™interprÃ©ter lâ€™Ã©volution du sentiment d'une semaine Ã  lâ€™autre, mÃªme avec des outils simples. Â»
:::


### ğŸ¤ Collaboration finale

Ã€ la fin du cours, une activitÃ© en classe permettra Ã  chaque Ã©tudiants/Ã©quipes de **partager son propre lexique de sentiments en franÃ§ais** construit durant lâ€™analyse. 

ğŸ“ **Lâ€™enseignant collectera et fusionnera ces lexiques**, en les vÃ©rifiant pour en retirer une version enrichie commune. Cette nouvelle version sera partagÃ©e avec toute la classe comme ressource collective pour les projets futurs.



## Ã‰tape 3 â€” Mots distinctifs

Dans cette Ã©tape, nous allons identifier les mots qui ressortent le plus chaque semaine. Pour cela, nous utiliserons l'approche **TF-IDF** (Term Frequency-Inverse Document Frequency), qui permet de mettre en Ã©vidence les mots Ã  la fois frÃ©quents dans un document et rares dans l'ensemble des documents.

::: {.callout-tip title="ğŸ§‘â€ğŸ’¼ - IdÃ©e dâ€™Anne-Sophie"}
Â« Un bon indicateur de ce que ressentent les Ã©tudiantÂ·es, ce sont les mots qui ressortent le plus dans leurs commentaires. Vous pouvez essayer une analyse TF-IDF ou mÃªme crÃ©er un nuage de mots. Â»
:::

::: {.callout-note title="ğŸ” Notions clÃ©s"}
- **TF (Term Frequency)**â€¯: frÃ©quence dâ€™apparition dâ€™un mot dans un document.
- **IDF (Inverse Document Frequency)**â€¯: importance inverse dâ€™un mot dans lâ€™ensemble des documents â€“ les mots rares ont un IDF Ã©levÃ©.
- **TFâ€‘IDF**â€¯: produit TF Ã— IDF qui met en Ã©vidence les mots Ã  la fois frÃ©quents dans un document et rares dans les autres (mots "distinctifs").
:::

### Calcul TF-IDF

Calculons le TF-IDF pour chaque mot par semaine :

```{r}
tfidf <- texte_nettoye %>%
  count(semaine, word) %>%
  bind_tf_idf(word, semaine, n) %>%
  arrange(desc(tf_idf))

head(tfidf)
```

### Visualisation pour une semaine donnÃ©e

Faisons un graphique pour visualiser les mots les plus distinctifs pour une semaine spÃ©cifique. Par exemple, la semaine 2 :

```{r}
# Choisir semaine 2 comme exemple
library(forcats)

tfidf %>%
  filter(semaine == 2) %>%
  slice_max(tf_idf, n = 8) %>%
  mutate(word = fct_reorder(word, tf_idf)) %>%
  ggplot(aes(x = word, y = tf_idf)) +
  geom_col(fill = "darkorange") +
  coord_flip() +
  labs(title = "Mots les plus distinctifs â€” Semaine 2",
       x = NULL, y = "TF-IDF")
```

Une visualisation comme celle-ci permet de voir quels mots sont les plus reprÃ©sentatifs des commentaires de cette semaine-lÃ . Il existe aussi la possibilitÃ© de crÃ©er un **nuage de mots** pour une reprÃ©sentation plus visuelle. Un nuage de mot est une reprÃ©sentation graphique des mots les plus frÃ©quents, oÃ¹ la taille de chaque mot est proportionnelle Ã  sa frÃ©quence d'apparition.

ğŸ’¡ Pour crÃ©er un nuage de mots en franÃ§ais :
- Utilisez la fonction `wordcloud()` du package `wordcloud`, ou `ggwordcloud` pour plus de personnalisation.
- Inspirez-vous de cet exemple complet : [https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html](https://cran.r-project.org/web/packages/wordcloud2/vignettes/wordcloud.html)

::: {.callout-important title="ğŸ§‘â€ğŸ’¼ - Question dâ€™Anne-Sophie"}
Â« Peux-tu repÃ©rer les mots qui ressortent le plus chaque semaine ? Tu pourrais essayer une approche TF-IDF et me faire un graphique ou mÃªme un nuage de mots. Â»
:::


## Ã‰tape 4 â€” CrÃ©ation du dashboard

Maintenant que nous avons nettoyÃ© les donnÃ©es et effectuÃ© les analyses de sentiment et de mots distinctifs, il est temps de crÃ©er un tableau de bord interactif. Celui-ci permettra Ã  Anne-Sophie de visualiser les rÃ©sultats de maniÃ¨re claire et dynamique.

::: {.callout-note title="ğŸ§‘â€ğŸ’¼ - Rappel dâ€™Anne-Sophie"}
Le tableau de bord final doit Ãªtre **clair, interactif et utile**. Un **modÃ¨le prÃªt Ã  lâ€™emploi (`Modele_Dashboardt.Rmd`)** se trouve dans le dÃ©pÃ´t GitHub du module. Personnalisezâ€‘leâ€¯: branchez vos propres donnÃ©es, ajustez les filtres, et ajoutez au moins deux visualisations.
:::
## Ã‰tape 5 â€” Recommandations et analyse finale

Ã€ la fin du tableau de bord, rÃ©digez un rÃ©sumÃ© de vos **observations clÃ©s**â€¯:

- Ã©volution du score de sentiment,
- semaines critiques,
- recommandations dâ€™action pour amÃ©liorer lâ€™expÃ©rience Ã©tudiante,
- **analyse des variables numÃ©riques** `difficulte`, `engagement`, `plaisir`â€¯: moyenne et tendance par semaine, comparaison avec le score de sentiment (ex. corrÃ©lations simples ou graphiques combinÃ©s).

::: {.callout-important title="ğŸ§‘â€ğŸ’¼ - DÃ©fi dâ€™Anne-Sophie"}
Â« Nâ€™oubliez pas dâ€™explorer les scores numÃ©riques. Comment le sentiment textuel se compareâ€‘tâ€‘il au niveau de plaisir ou de difficultÃ© perÃ§ueâ€¯? PrÃ©sentez au moins une visualisation qui croise ces informations. Â»
:::

# ğŸŒŸ Bonus â€” Personnalisation â€” Personnalisation

Voici quelques idÃ©es pour aller plus loin dans la personnalisation de votre tableau de bord :

- Ajouter le **logo de la FacultÃ© des sciences et de gÃ©nie** ou de lâ€™UniversitÃ© Laval,
- Personnaliser la **palette de couleurs** pour quâ€™elle soit cohÃ©rente avec lâ€™identitÃ© visuelle ULaval,
- Ajouter une **photo de fond** discrÃ¨te dans lâ€™en-tÃªte,
- Ajouter une citation inspirante ou un message d'accueil dans la barre latÃ©rale.

ğŸ’¡ Vous pouvez Ã©galement intÃ©grer une barre de progression ou un indicateur visuel du sentiment gÃ©nÃ©ral par semaine.

# ğŸ“¤ Livraison attendue

- Un dÃ©pÃ´t GitHub contenant :
  - le `.Rmd` du tableau de bord,
  - le rendu HTML final,
  - le fichier de donnÃ©es nettoyÃ© (si modifiÃ©).
- **Le tableau de bord doit Ãªtre dÃ©ployÃ© (par exemple via Shinyapp.io ou Posit Cloud)** et le lien final envoyÃ© Ã  **Anne-Sophie (la vÃ©ritable directrice du programme)**.

# ğŸ§  Conseils dâ€™Anne-Sophie

> Â« Un bon tableau de bord, câ€™est comme un bon pitch : **clair, lisible et ciblÃ©**. Mettez-vous Ã  la place de votre utilisateur final. Â»
